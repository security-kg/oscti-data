<!DOCTYPE html>
<html lang="en-US">

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
	<title>When AIs Start Hacking - Schneier on Security</title>
	<meta name='robots' content='max-image-preview:large' />
<link rel='dns-prefetch' href='//s.w.org' />
<link rel='dns-prefetch' href='//c0.wp.com' />
<link rel="alternate" type="application/rss+xml" title="Schneier on Security &raquo; Feed" href="https://www.schneier.com/feed/" />
<link rel="alternate" type="application/rss+xml" title="Schneier on Security &raquo; Comments Feed" href="https://www.schneier.com/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Schneier on Security &raquo; When AIs Start Hacking Comments Feed" href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/feed/" />
<link rel='stylesheet' id='wp-block-library-css'  href='https://c0.wp.com/c/5.7.1/wp-includes/css/dist/block-library/style.min.css' type='text/css' media='all' />
<style id='wp-block-library-inline-css' type='text/css'>
.has-text-align-justify{text-align:justify;}
</style>
<style id='woocommerce-inline-inline-css' type='text/css'>
.woocommerce form .form-row .required { visibility: visible; }
</style>
<link rel='stylesheet' id='schneier-css'  href='https://149400697.v2.pressablecdn.com/wp-content/themes/schneier/style.css?ver=1.0.0' type='text/css' media='all' />
<link rel='stylesheet' id='schneier-main-css'  href='https://149400697.v2.pressablecdn.com/wp-content/themes/schneier/assets/dist/css/style.css?ver=1.0.3' type='text/css' media='all' />
<link rel='stylesheet' id='jetpack_css-css'  href='https://c0.wp.com/p/jetpack/9.6.1/css/jetpack.css' type='text/css' media='all' />
<script type='text/javascript' src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js?ver=3.5.1' id='jquery-js'></script>
<link rel="https://api.w.org/" href="https://www.schneier.com/wp-json/" /><link rel="alternate" type="application/json" href="https://www.schneier.com/wp-json/wp/v2/posts/62199" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://www.schneier.com/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://www.schneier.com/wp-includes/wlwmanifest.xml" /> 

<link rel="canonical" href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html" />
<link rel='shortlink' href='https://www.schneier.com/?p=62199' />
<link rel="alternate" type="application/json+oembed" href="https://www.schneier.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fwww.schneier.com%2Fblog%2Farchives%2F2021%2F04%2Fwhen-ais-start-hacking.html" />
<link rel="alternate" type="text/xml+oembed" href="https://www.schneier.com/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fwww.schneier.com%2Fblog%2Farchives%2F2021%2F04%2Fwhen-ais-start-hacking.html&#038;format=xml" />
	<noscript><style>.woocommerce-product-gallery{ opacity: 1 !important; }</style></noscript>
	<link rel="icon" href="https://149400697.v2.pressablecdn.com/wp-content/uploads/2020/06/cropped-favicon-1-32x32.png" sizes="32x32" />
<link rel="icon" href="https://149400697.v2.pressablecdn.com/wp-content/uploads/2020/06/cropped-favicon-1-192x192.png" sizes="192x192" />
<link rel="apple-touch-icon" href="https://149400697.v2.pressablecdn.com/wp-content/uploads/2020/06/cropped-favicon-1-180x180.png" />
<meta name="msapplication-TileImage" content="https://149400697.v2.pressablecdn.com/wp-content/uploads/2020/06/cropped-favicon-1-270x270.png" />
		<style type="text/css" id="wp-custom-css">
			#schneier_promotion-2 img {
    max-width: 180px;
}		</style>
		</head>

<body class="post-template-default single single-post postid-62199 single-format-standard theme-schneier woocommerce-no-js">

	<div id="wrapper">
		<div id="main">

			<header>
				<div id="header">
					<h1>
						<a href="https://www.schneier.com/" rel="home">
							Schneier on Security						</a>
					</h1>
				</div>
			</header>

			<nav>
				<div class="nav" id="header-nav">
					<div class="menu-main-menu-container"><ul id="menu-main-menu" class="menu"><li id="menu-item-50175" class="menu1 menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-50175 current-menu-item"><a href="https://www.schneier.com">Blog</a></li>
<li id="menu-item-50916" class="menu2 menu-item menu-item-type-post_type menu-item-object-page menu-item-50916"><a href="https://www.schneier.com/crypto-gram/">Newsletter</a></li>
<li id="menu-item-50166" class="menu3 menu-item menu-item-type-post_type menu-item-object-page menu-item-50166"><a href="https://www.schneier.com/books/">Books</a></li>
<li id="menu-item-50169" class="menu4 menu-item menu-item-type-custom menu-item-object-custom menu-item-50169"><a href="https://www.schneier.com/essays/">Essays</a></li>
<li id="menu-item-50170" class="menu5 menu-item menu-item-type-custom menu-item-object-custom menu-item-50170"><a href="https://www.schneier.com/news/">News</a></li>
<li id="menu-item-50171" class="menu6 menu-item menu-item-type-custom menu-item-object-custom menu-item-50171"><a href="https://www.schneier.com/talks/">Talks</a></li>
<li id="menu-item-50167" class="menu7 menu-item menu-item-type-post_type menu-item-object-page menu-item-50167"><a href="https://www.schneier.com/academic/">Academic</a></li>
<li id="menu-item-50174" class="menu8 menu-item menu-item-type-post_type menu-item-object-page menu-item-50174"><a href="https://www.schneier.com/blog/about/">About Me</a></li>
</ul></div>				</div>
			</nav>

			
<aside>
	<div class="sidebar" id="sidebar-one">
		<section><div class="sidesection widget widget_schneier_search" id="schneier_search-3"><h3>Search</h3>
<p class="small">
	<em>Powered by <a href="https://duckduckgo.com/">DuckDuckGo</a></em></p>

<form method="get" action="https://duckduckgo.com/">

	<input type="hidden" name="kh" value="1" /><!-- use https -->

	<input id="search" name="q" size="15" maxlength="255" />

	<input type="submit" value="Go" /><br>

	<input type="radio" name="sites" id="searchblog" value="www.schneier.com/blog" />
	<label for="searchblog">Blog</label>

	<input type="radio" name="sites" id="searchessays" value="www.schneier.com/essays" />
	<label for="searchessays">Essays</label>

	<input type="radio" name="sites" id="searchall" value="www.schneier.com" checked="" />
	<label for="searchall">Whole site</label>

</form>
</div></section><section><div class="sidesection widget widget_schneier_social" id="schneier_social-2"><h3>Subscribe</h3>
<div id="subscription-buttons">

	<a href="https://www.schneier.com/feed/atom"><img src="https://149400697.v2.pressablecdn.com/wp-content/uploads/2019/10/rss-32px.png" alt="Atom Feed" /></a><a href="https://www.facebook.com/bruce.schneier"><img src="https://149400697.v2.pressablecdn.com/wp-content/uploads/2019/10/facebook-32px.png" alt="Facebook" /></a><a href="https://twitter.com/schneierblog/"><img src="https://149400697.v2.pressablecdn.com/wp-content/uploads/2019/10/twitter-32px.png" alt="Twitter" /></a><a href="https://www.amazon.com/Schneier-on-Security/dp/B0053HDDWW/"><img src="https://149400697.v2.pressablecdn.com/wp-content/uploads/2019/10/kindle-32px.png" alt="Kindle" /></a><a href="https://www.schneier.com/crypto-gram"><img src="https://149400697.v2.pressablecdn.com/wp-content/uploads/2019/10/email-32px.png" alt="E-Mail Newsletter (Crypto-Gram)" /></a>
</div>
</div></section>	</div>
</aside>

			<div id="content">

				
		<p id="breadcrumbs">

			<a href="https://www.schneier.com">Home</a><a href="https://www.schneier.com/blog/archives/">Blog</a>		</p>

		
<article id="post-62199" class="post-62199 post type-post status-publish format-standard hentry category-uncategorized tag-artificial-intelligence tag-essays tag-hacking tag-vulnerabilities">

	<div class="article">

		<h2 class="entry">When AIs Start Hacking</h2>
		<p>If you don&#8217;t have enough to worry about already, consider a world where AIs are hackers.</p>
<p>Hacking is as old as humanity. We are creative problem solvers. We exploit loopholes, manipulate systems, and strive for more influence, power, and wealth. To date, hacking has exclusively been a human activity. Not for long.</p>
<p>As I lay out in a <a href="https://www.belfercenter.org/publication/coming-ai-hackers">report I just published</a>, artificial intelligence will eventually find vulnerabilities in all sorts of social, economic, and political systems, and then exploit them at unprecedented speed, scale, and scope. After hacking humanity, AI systems will then hack other AI systems, and humans will be little more than collateral damage.</p>
<p>Okay, maybe this is a bit of hyperbole, but it requires no far-future science fiction technology. I&#8217;m not postulating an AI &#8220;singularity,&#8221; where the AI-learning feedback loop becomes so fast that it outstrips human understanding. I&#8217;m not assuming intelligent androids. I&#8217;m not assuming evil intent. Most of these hacks don&#8217;t even require major research breakthroughs in AI. They&#8217;re already happening. As AI gets more sophisticated, though, we often won&#8217;t even know it&#8217;s happening.</p>
<p>AIs don&#8217;t solve problems like humans do. They look at more types of solutions than us. They&#8217;ll go down complex paths that we haven&#8217;t considered. This can be an issue because of something called the explainability problem. Modern AI systems are essentially black boxes. Data goes in one end, and an answer comes out the other. It can be impossible to understand how the system reached its conclusion, even if you&#8217;re a programmer looking at the code.</p>
<p>In 2015, a research group fed an AI system called Deep Patient health and medical data from some 700,000 people, and tested whether it could predict diseases. It could, but Deep Patient provides no explanation for the basis of a diagnosis, and the researchers have no idea how it comes to its conclusions. A doctor either can either trust or ignore the computer, but that trust will remain blind.</p>
<p>While researchers are working on AI that can explain itself, there seems to be a trade-off between capability and explainability. Explanations are a cognitive shorthand used by humans, suited for the way humans make decisions. Forcing an AI to produce explanations might be an additional constraint that could affect the quality of its decisions. For now, AI is becoming more and more opaque and less explainable.</p>
<p>Separately, AIs can engage in something called reward hacking. Because AIs don&#8217;t solve problems in the same way people do, they will invariably stumble on solutions we humans might never have anticipatedÂ­ &#8212; and some will subvert the intent of the system. That&#8217;s because AIs don&#8217;t think in terms of the implications, context, norms, and values we humans share and take for granted. This reward hacking involves achieving a goal but in a way the AI&#8217;s designers neither wanted nor intended.</p>
<p>Take a soccer simulation where an AI figured out that if it kicked the ball out of bounds, the goalie would have to throw the ball in and leave the goal undefended. Or another simulation, where an AI figured out that instead of running, it could make itself tall enough to cross a distant finish line by falling over it. Or the robot vacuum cleaner that instead of learning to not bump into things, it learned to drive backwards, where there were no sensors telling it it was bumping into things. If there are problems, inconsistencies, or loopholes in the rules, and if those properties lead to an acceptable solution as defined by the rules, then AIs will find these hacks.</p>
<p>We learned about this hacking problem as children with the story of King Midas. When the god Dionysus grants him a wish, Midas asks that everything he touches turns to gold. He ends up starving and miserable when his food, drink, and daughter all turn to gold. It&#8217;s a specification problem: Midas programmed the wrong goal into the system.</p>
<p>Genies are very precise about the wording of wishes, and can be maliciously pedantic. We know this, but there&#8217;s still no way to outsmart the genie. Whatever you wish for, he will always be able to grant it in a way you wish he hadn&#8217;t. He will hack your wish. Goals and desires are always underspecified in human language and thought. We never describe all the options, or include all the applicable caveats, exceptions, and provisos. Any goal we specify will necessarily be incomplete.</p>
<p>While humans most often implicitly understand context and usually act in good faith, we can&#8217;t completely specify goals to an AI. And AIs won&#8217;t be able to completely understand context.</p>
<p>In 2015, Volkswagen was caught cheating on emissions control tests. This wasn&#8217;t AI &#8212; human engineers programmed a regular computer to cheat &#8212; but it illustrates the problem. They programmed their engine to detect emissions control testing, and to behave differently. Their cheat remained undetected for years.</p>
<p>If I asked you to design a car&#8217;s engine control software to maximize performance while still passing emissions control tests, you wouldn&#8217;t design the software to cheat without understanding that you were cheating. This simply isn&#8217;t true for an AI. It will think &#8220;out of the box&#8221; simply because it won&#8217;t have a conception of the box. It won&#8217;t understand that the Volkswagen solution harms others, undermines the intent of the emissions control tests, and is breaking the law. Unless the programmers specify the goal of not behaving differently when being tested, an AI might come up with the same hack. The programmers will be satisfied, the accountants ecstatic. And because of the explainability problem, no one will realize what the AI did. And yes, knowing the Volkswagen story, we can explicitly set the goal to avoid that particular hack. But the lesson of the genie is that there will always be unanticipated hacks.</p>
<p>How realistic is AI hacking in the real world? The feasibility of an AI inventing a new hack depends a lot on the specific system being modeled. For an AI to even start on optimizing a problem, let alone hacking a completely novel solution, all of the rules of the environment must be formalized in a way the computer can understand. Goals &#8212; known in AI as objective functions &#8212; need to be established. And the AI needs some sort of feedback on how well it&#8217;s doing so that it can improve.</p>
<p>Sometimes this is simple. In chess, the rules, objective, and feedback &#8212; did you win or lose? &#8212; are all precisely specified. And there&#8217;s no context to know outside of those things that would muddy the waters. This is why most of the current examples of goal and reward hacking come from simulated environments. These are artificial and constrained, with all of the rules specified to the AI. The inherent ambiguity in most other systems ends up being a near-term security defense against AI hacking.</p>
<p>Where this gets interesting are systems that are well specified and almost entirely digital. Think about systems of governance like the tax code: a series of algorithms, with inputs and outputs. Think about financial systems, which are more or less algorithmically tractable.</p>
<p>We can imagine equipping an AI with all of the world&#8217;s laws and regulations, plus all the world&#8217;s financial information in real time, plus anything else we think might be relevant; and then giving it the goal of &#8220;maximum profit.&#8221; My guess is that this isn&#8217;t very far off, and that the result will be all sorts of novel hacks.</p>
<p>But advances in AI are discontinuous and counterintuitive. Things that seem easy turn out to be hard, and things that seem hard turn out to be easy. We don&#8217;t know until the breakthrough occurs.</p>
<p>When AIs start hacking, everything will change. They won&#8217;t be constrained in the same ways, or have the same limits, as people. They&#8217;ll change hacking&#8217;s speed, scale, and scope, at rates and magnitudes we&#8217;re not ready for. AI text generation bots, for example, will be replicated in the millions across social media. They will be able to engage on issues around the clock, sending billions of messages, and overwhelm any actual online discussions among humans. What we will see as boisterous political debate will be bots arguing with other bots. They&#8217;ll artificially influence what we think is normal, what we think others think.</p>
<p>The increasing scope of AI systems also makes hacks more dangerous. AIs are already making important decisions about our lives, decisions we used to believe were the exclusive purview of humans: Who gets parole, receives bank loans, gets into college, or gets a job. As AI systems get more capable, society will cede more &#8212; and more important &#8212; decisions to them. Hacks of these systems will become more damaging.</p>
<p>What if you fed an AI the entire US tax code? Or, in the case of a multinational corporation, the entire world&#8217;s tax codes? Will it figure out, without being told, that it&#8217;s smart to incorporate in Delaware and register your ship in Panama? How many loopholes will it find that we don&#8217;t already know about? Dozens? Thousands? We have no idea.</p>
<p>While we have societal systems that deal with hacks, those were developed when hackers were humans, and reflect human speed, scale, and scope. The IRS cannot deal with dozens &#8212; let alone thousands &#8212; of newly discovered tax loopholes. An AI that discovers unanticipated but legal hacks of financial systems could upend our markets faster than we could recover.</p>
<p>As I discuss in <a href="https://www.belfercenter.org/publication/coming-ai-hackers">my report</a>, while hacks can be used by attackers to exploit systems, they can also be used by defenders to patch and secure systems. So in the long run, AI hackers will favor the defense because our software, tax code, financial systems, and so on can be patched before they&#8217;re deployed. Of course, the transition period is dangerous because of all the legacy rules that will be hacked. There, our solution has to be resilience.</p>
<p>We need to build resilient governing structures that can quickly and effectively respond to the hacks. It won&#8217;t do any good if it takes years to update the tax code, or if a legislative hack becomes so entrenched that it can&#8217;t be patched for political reasons. This is a hard problem of modern governance. It also isn&#8217;t a substantially different problem than building governing structures that can operate at the speed and complexity of the information age.</p>
<p>What I&#8217;ve been describing is the interplay between human and computer systems, and the risks inherent when the computers start doing the part of humans. This, too, is a more general problem than AI hackers. It&#8217;s also one that technologists and futurists are writing about. And while it&#8217;s easy to let technology lead us into the future, we&#8217;re much better off if we as a society decide what technology&#8217;s role in our future should be.</p>
<p>This is all something we need to figure out now, before these AIs come online and start hacking our world.</p>
<p>This essay <a href="https://www.wired.com/story/opinion-hackers-used-to-be-humans-soon-ais-will-hack-humanity/">previously appeared</a> on Wired.com</p>

		
			<p class="entry-tags">
				<span class="tags-links">Tags: <a href="https://www.schneier.com/tag/artificial-intelligence/" rel="tag">artificial intelligence</a>, <a href="https://www.schneier.com/tag/essays/" rel="tag">essays</a>, <a href="https://www.schneier.com/tag/hacking/" rel="tag">hacking</a>, <a href="https://www.schneier.com/tag/vulnerabilities/" rel="tag">vulnerabilities</a></span>			</p>

		
		
		<p class="posted">
			<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html" rel="bookmark">Posted on April 26, 2021 at 6:06 AM</a>			â€¢
			<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html#comments">29 Comments</a>		</p>

		<aside><div class="schneier-share share" data-uri="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html" data-title="When AIs Start Hacking" data-order="facebook twitter tumblr" data-social-share-privacy="true" /></aside>
	</div>

</article>


	<h3 id="comments">Comments</h3>

	
		<article class="comment even thread-even depth-1" id="comment-373358">

			<div class="comment by-leon ">

				<p class="commentcredit">

					<span class="commenter">LÃ©on</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373358">
						April 26, 2021 6:35 AM					</a>

				</p>

				<p>No. AI is a misleading term. AI systems are still computers we need to program. Not with a program code this time, but with a model that we need to train.</p>
<p>For a AI to recognise a red car, we need to train the model with images of cars, all sizes and shapes and all colours. And then tell the AI system after each &#8220;recognition&#8221; whether is was indeed a car and whether it was indeed red or not.</p>
<p>By the way: if one could design an AI for detecting security vulnerabilities, one could also use it in software engineering.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373368">

			<div class="comment by-jones ">

				<p class="commentcredit">

					<span class="commenter"><a href='http://telesio.wordpress.com' rel='external nofollow ugc' class='url'>jones</a></span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373368">
						April 26, 2021 6:57 AM					</a>

				</p>

				<p>This is our manifest destiny:</p>
<p><a href="http://subproject119.appliedchaosdynamicscontrolassociation.net" rel="nofollow ugc">http://subproject119.appliedchaosdynamicscontrolassociation.net</a></p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373369">

			<div class="comment by-petre-peter ">

				<p class="commentcredit">

					<span class="commenter">Petre Peter</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373369">
						April 26, 2021 7:02 AM					</a>

				</p>

				<p>How much of our world should be governed by technology? How do we punish an AI if it turns to the dark  side? This is a new form of tyranny that starts with &#8220;the computer won&#8217;t let me do it&#8221;. An excuse to not accommodate exceptions or anomalies. We will have no choice but to think and act the same which is our biggest threat to liberty. The AI doesn&#8217;t even have to do real computation. It can just be a tyrant using the &#8216;say&#8217; command.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373377">

			<div class="comment by-metaschima ">

				<p class="commentcredit">

					<span class="commenter">metaschima</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373377">
						April 26, 2021 7:18 AM					</a>

				</p>

				<p>@LÃ©on</p>
<p>I agree, what most people call AI is a neural network (real or virtual) that is trained on a dataset and with time gains the ability to solve a problem. Although it is able to learn, we are still teaching it. True AI would be a system that learns on its own and starts making decisions on its own. So far true AI does not exist, but that may change in the near future. True AI is indeed the making of many a sci-fi horror.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373393">

			<div class="comment by-whiskersinmenlo ">

				<p class="commentcredit">

					<span class="commenter">WhiskersInMenlo</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373393">
						April 26, 2021 8:34 AM					</a>

				</p>

				<p>It is necessary to add compilers and language specifications to this discussion.</p>
<p>Compilers can alter the program in ways most programmers and yes security professionals might not expect.</p>
<p>Add hardware: Hardware prefetches data often before authorization code evaluates as true or false.</p>
<p>Systems are built to multiple organizational specifications and commonly fails at these organizational boundaries.</p>
<p>Yes test systems will be increasingly successful at discovering known issues quicker in real code.</p>
<p>Will AI systems see all the source code or only the binary or only public  and private interfaces.  Will the AI be rich in stupid user tricks, and ambiguous instruction lore?</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373397">

			<div class="comment by-jimbo ">

				<p class="commentcredit">

					<span class="commenter">Jimbo</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373397">
						April 26, 2021 8:58 AM					</a>

				</p>

				<p>The tax system perhaps is not a good example.  There are no loop holes &#8211; everything in the internal revenue code is put there intentionally, passed by congress after lenghtly debates and signed into law by the president.</p>
<p>This quote from Judge Learned Hand sums it up:<br />
Anyone may arrange his affairs so that his taxes shall be as low as possible; he is not bound to choose that pattern which best pays the treasury. There is not even a patriotic duty to increase one&#8217;s taxes. Over and over again the Courts have said that there is nothing sinister in so arranging affairs as to keep taxes as low as possible. Everyone does it, rich and poor alike and all do right, for nobody owes any public duty to pay more than the law demands.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373398">

			<div class="comment by-cdrjameson ">

				<p class="commentcredit">

					<span class="commenter">CdrJameson</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373398">
						April 26, 2021 9:06 AM					</a>

				</p>

				<p>Hello, I&#8217;m a game developer. We use AIs to try and break the games, find holes in the rules and pathological states. They&#8217;re very good at it.</p>
<p>It&#8217;s not a massively widespread practice as far as I know, but it&#8217;s a fairly obvious one (just an extension of random fuzz testing) and it&#8217;s pretty cheap.<br />
It&#8217;s not particularly new either &#8211; both the 1981 and 1982 Traveller Trillion Credit Squadron championships were won by AIs that found holes in the rules.</p>
<p>And these are entirely formally defined mathematical systems, so they can be tweaked to be fixed, but good luck with that one in the real world.</p>
<p>It&#8217;s interesting to see AI advances being tried out in games. It&#8217;s also a piece of sleight-of-hand to then imply you can generalise that to the real world. Just the Ludic Fallacy in action kids! And that already crashed the economy once, in 2008.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373400">

			<div class="comment by-hedo ">

				<p class="commentcredit">

					<span class="commenter">Hedo</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373400">
						April 26, 2021 9:14 AM					</a>

				</p>

				<p>Remember September 11th 2001 (or the WW2 Japanese Kamikaze)? Airplanes were not designed to be intentionally flown into buildings yet people did use them for that terrible purpose. Why do so many think that we/us humans are actually doing/bringing anything to the table when it comes to planet Earth? Seriously. Just look at us. Greed. Hate. Envy. Jealousy. Narcissist. Angry. Mad. Malicious. Too passive. Too ignorant. There is a &#8220;Pile&#8221; or a &#8220;Bucket&#8221; for each and every one of us. We do not deserve this beautiful planet.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373401">

			<div class="comment by-pete ">

				<p class="commentcredit">

					<span class="commenter">pete</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373401">
						April 26, 2021 9:15 AM					</a>

				</p>

				<p>There has been a fair bit of sci-fi written about this &#8211; most notably James P. Hogan&#8217;s &#8220;The Two Faces of Tomorrow&#8221; which opens with an AI making an efficient decision about removing an obstacle to a construction project on the Moon that is not a good decision for the survey team that had just reported the obstacle.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373402">

			<div class="comment by-fred-fubar ">

				<p class="commentcredit">

					<span class="commenter">Fred Fubar</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373402">
						April 26, 2021 10:01 AM					</a>

				</p>

				<p>I had to tell a friend that it&#8217;s incredibly unfair he can read &#8220;The Futurological Congress&#8221; and Tichy&#8217;s reports on same in the original language after reading this essay.</p>
<p>Schneier&#8217;s reality vs. Lem&#8217;s satire. What a choice!</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373403">

			<div class="comment by-willmore ">

				<p class="commentcredit">

					<span class="commenter">willmore</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373403">
						April 26, 2021 10:05 AM					</a>

				</p>

				<p>Ahh, good old Kuang Eleven.</p>
<p>@LÃ©on, you&#8217;re thinking of machine learning. There are other types of AI programs that work differently.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373405">

			<div class="comment by-vesselin-bontchev ">

				<p class="commentcredit">

					<span class="commenter">Vesselin Bontchev</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373405">
						April 26, 2021 10:45 AM					</a>

				</p>

				<p>Bruce, AI is a vast field (much larger than infosec) and you&#8217;re confusing different kinds of AI.</p>
<p>The kind of AI that can&#8217;t explain its decisions is ML (machine learning). It will <em>never</em> be able to explain its decisions. You give a neural network a bunch of positive and negative examples and it reconfigures the weights of the neurons, starting to recognize patterns that humans often don&#8217;t see, and produces an answer based on these patterns. It&#8217;s not sentient, it doesn&#8217;t reason, it can&#8217;t explain how it has reached a conclusion. It just finds hidden patterns.</p>
<p>Another kind of AI is expert systems. These most definitely <em>can</em> explain their reasoning. They have built-in abilities to answer the questions &#8220;Why?&#8221; (&#8220;why exactly was this conclusion reached?&#8221; and &#8220;How?&#8221; (&#8220;what particular rules triggered that lead to this conclusion?&#8221;.</p>
<p>It&#8217;s just the ML is <em>easy</em> &#8211; that&#8217;s why it&#8217;s so widespread nowadays. You cobble together a neural network, you throw a bunch of data at it, it starts producing results. The only tricky part is decided what properties of the data to feed it.</p>
<p>Expert systems require a lot of manual work. You have to extract the knowledge from human experts (who don&#8217;t have it systematized and often rely on intuition or half-forgotten experience) and formalize it as a humongous set of &#8220;if-then-else&#8221; rules. It can take years to build one &#8211; and you might still fail, if you don&#8217;t get the right experts or don&#8217;t have the talent to extract their knowledge.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373407">

			<div class="comment by-evilkiru ">

				<p class="commentcredit">

					<span class="commenter">EvilKiru</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373407">
						April 26, 2021 11:04 AM					</a>

				</p>

				<p>@Moderator: heil Putin â€¢ April 26, 2021 10:44 AM looks to be either spam or a hack attempt?</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373408">

			<div class="comment by-johnnys ">

				<p class="commentcredit">

					<span class="commenter">JohnnyS</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373408">
						April 26, 2021 11:09 AM					</a>

				</p>

				<p>&#8220;So in the long run, AI hackers will favor the defense because our software, tax code, financial systems, and so on can be patched before theyâ€™re deployed.&#8221;</p>
<p>Modern software is barely checked for insecurities now before shipping: Why would that change? Without responsibility assigned for software security, there is no software security.</p>
<p>I expect that any AI applied to checking software for defensive purposes will at best be an excuse to run some &#8220;tool&#8221; against the software, so anyone responsible can then say &#8220;I checked it for problems: The tool said it was OK!&#8221; With that excuse they achieve CYA, whether the &#8220;tool&#8221; is any good or not, so there is little incentive to spend money on a good &#8220;tool&#8221;. It remains nothing more than theater.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373410">

			<div class="comment by-paul ">

				<p class="commentcredit">

					<span class="commenter"><a href='https://imgur.com/a/IrTMxkl' rel='external nofollow ugc' class='url'>Paul</a></span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373410">
						April 26, 2021 11:28 AM					</a>

				</p>

				<p>I hope Bruce can trim out the kiddie&#8217;s little Unicode toy in the pic:<br />
<a href="https://imgur" rel="nofollow ugc">https://imgur</a> [DOT] com/a/IrTMxkl</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373412">

			<div class="comment by-j ">

				<p class="commentcredit">

					<span class="commenter">J</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373412">
						April 26, 2021 11:37 AM					</a>

				</p>

				<p>In Germany we not only have cheating car manufacturers (and not only VW, the others were just more careful to include some plausible deniability).  We also have banks who defraud the state by claiming multiple tax refunds for a tax paid only once: <a href="https://en.wikipedia.org/wiki/CumEx-Files" rel="nofollow ugc">https://en.wikipedia.org/wiki/CumEx-Files</a><br />
AFAIK no AIs were involved.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373413">

			<div class="comment by-mark ">

				<p class="commentcredit">

					<span class="commenter"><a href='https://mrw.5-cent.us' rel='external nofollow ugc' class='url'>mark</a></span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373413">
						April 26, 2021 11:48 AM					</a>

				</p>

				<p>About the robot vacuum cleaner &#8211; that&#8217;s the same problem, except this is a failure of the programmers to consider what the box they&#8217;re working in <em>is</em>.</p>
<p>Decades ago, Radio Shack had a little robot, It would run into something, look around, and go at -&gt;right angles&lt;- to whatever it ran into. Why is it that no robot vacuum plots the room its in, so as to not go over a spot more than once, and cover the entire room, instead of only random parts?</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373415">

			<div class="comment by-impossibly-stupid ">

				<p class="commentcredit">

					<span class="commenter"><a href='https://www.impossiblystupid.com' rel='external nofollow ugc' class='url'>Impossibly Stupid</a></span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373415">
						April 26, 2021 12:21 PM					</a>

				</p>

				<blockquote><p>
  AIs donâ€™t solve problems like humans do.
</p></blockquote>
<p>As other&#8217;s have noted, Bruce, you do a great disservice when you conflate the current state of popular machine learning algorithms with the whole of artificial intelligence.  The crux of the problem is that ML doesn&#8217;t solve problems at all, it merely satisfies constraints.  You&#8217;ve written about the security flaws that that leads to countless times (usually found via <a href="https://en.wikipedia.org/wiki/Adversarial_machine_learning" rel="nofollow ugc">adversarial machine learning</a>).</p>
<blockquote><p>
  Separately, AIs can engage in something called reward hacking.
</p></blockquote>
<p>That is not something limited to machines.  Humans successfully gamed societal systems for millennia.  Yes, ML offers new tools in our toolbox (e.g., ways to automate said exploits at scale), but it doesn&#8217;t fundamentally alter the fact we often times <em>intentionally</em> design flawed systems.</p>
<blockquote><p>
  Genies are very precise about the wording of wishes, and can be maliciously pedantic.
</p></blockquote>
<p>I think the introduction of magical thinking is very apt here.  I mean that in a big way.  My academic background is in AI, but I also had quite a bit of interest in magic tricks when I was younger (with <a href="https://en.wikipedia.org/wiki/James_Randi" rel="nofollow ugc">James Randi</a> being a nice intersection with pseudoscientific thinking).  Modern machine learning <em>is</em> a trick, not genuine, &#8220;strong&#8221; AI.  We need to stop fooling ourselves into thinking it is as good, or as bad, as we imagine it to be.</p>
<blockquote><p>
  This wasnâ€™t AI â€” human engineers programmed a regular computer to cheat â€” but it illustrates the problem.
</p></blockquote>
<p>Sadly, it only illustrates a first-order problem.  As I said above, we humans not only think of ways to break the rules, we actively engage in breaking the <em>systems</em> that impose the rules.  ML will have nothing on us until it is able to hire lobbyists and bribe corrupt politicians to create rules that are inherently unfair.  The inequity is already operating at the meta level; these ML are just fighting over table scraps.</p>
<blockquote><p>
  My guess is that this isnâ€™t very far off, and that the result will be all sorts of novel hacks.
</p></blockquote>
<p>Nope.  The result is simply going to be the self-serving &#8220;hacks&#8221; that were intentionally put there by monied interests, but now you offer the possibility of them being exploited by everyone (or at least those who have access to the technology, in a very &#8220;Click Here to Kill Everybody&#8221; kind of way).</p>
<blockquote><p>
  They will be able to engage on issues around the clock, sending billions of messages, and overwhelm any actual online discussions among humans.
</p></blockquote>
<p>Already happening.  No ML needed, because humans are quite happy make fools of themselves on social media.  Even Elisa-level unsophisticated chat bots are enough to rile up the masses.  We&#8217;re rapidly approaching a tipping point where either a large segment of the population is lost to irrational thinking, or they realize how damaging social media is and just walk away.</p>
<blockquote><p>
  An AI that discovers unanticipated but legal hacks of financial systems could upend our markets faster than we could recover.
</p></blockquote>
<p>Again, humans are doing this now; don&#8217;t fool yourself into thinking you only need to pay attention when an &#8220;AI&#8221; is involved.  The whole <a href="https://en.wikipedia.org/wiki/GameStop_short_squeeze" rel="nofollow ugc">Robinhood/GameStop attack</a> that recently happened is a prime example.  Everyone dead set at screwing everyone else on the trading floor, but the people that make the rules still always win in the end.</p>
<blockquote><p>
  So in the long run, AI hackers will favor the defense because our software, tax code, financial systems, and so on can be patched before theyâ€™re deployed.
</p></blockquote>
<p>Unfortunately, as I said, those flaws are intentional.  Bought and paid for by people who do <em>not</em> want them fixed.  If your &#8220;AI&#8221; favors their defense, it only means the inequity in the system will get increasingly more polarizing, and it will only lead to solutions that are . . . non-digital.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373416">

			<div class="comment by-edward ">

				<p class="commentcredit">

					<span class="commenter">Edward</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373416">
						April 26, 2021 12:36 PM					</a>

				</p>

				<p>Somewhat connected and also <a href="https://geneticliteracyproject.org/2021/04/22/artificial-intelligence-is-teaching-robots-to-evolve-autonomously-so-they-can-pioneer-exploration-on-distant-planets/" rel="nofollow ugc">interesting.</a></p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373418">

			<div class="comment by-jon ">

				<p class="commentcredit">

					<span class="commenter">Jon</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373418">
						April 26, 2021 1:25 PM					</a>

				</p>

				<p>Personally, I&#8217;m reminded of the &#8216;Go&#8217; playing computer program that figured out how to always win:  It would place a bead at some ridiculous location (the rules specified an infinite board) which caused all the other programs to expand their memory footprint &#8211; but they didn&#8217;t have enough memory, and so crashed, and the miscreant always won (the rules specifying that a program that crashed had lost).</p>
<p>Predictable in afterthought, of course&#8230;  J.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373425">

			<div class="comment by-jeff ">

				<p class="commentcredit">

					<span class="commenter">Jeff</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373425">
						April 26, 2021 3:36 PM					</a>

				</p>

				<p>@mark. The recent versions of iRobot (Roomba) do plot the room and don&#8217;t do it randomly.  Also when complete, it sends me a diagram of what it covered,</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373426">

			<div class="comment by-anders ">

				<p class="commentcredit">

					<span class="commenter">Anders</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373426">
						April 26, 2021 3:40 PM					</a>

				</p>

				<p>@ALL</p>
<p>I think we have a first AI here.</p>
<p>hxxps://www.livescience.com/55164-russian-robot-escapes-lab-again.html</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373427">

			<div class="comment by-humdee ">

				<p class="commentcredit">

					<span class="commenter">Humdee</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373427">
						April 26, 2021 4:58 PM					</a>

				</p>

				<p>What is the distinction between &#8220;the explainability problem&#8221; and &#8220;a woman&#8217;s intuition&#8221;? I&#8217;m only half joking. Maybe the problem is that our brains already act like AI&#8217;s act but we dismissed that powerful ability because it would not allow us to play the language game of the giving and taking of reasons. Maybe it is time for the Age of Enlightenment to die.</p>
<p>&#8220;The heart has reasons that reason does not know.&#8221; Intuition? Or AI?</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373429">

			<div class="comment by-clive-robinson ">

				<p class="commentcredit">

					<span class="commenter">Clive Robinson</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373429">
						April 26, 2021 5:51 PM					</a>

				</p>

				<p>@ Bruce, All,</p>
<blockquote><p>Whatever you wish for, he [the Genie] will always be able to grant it in a way you wish he hadnâ€™t.</p></blockquote>
<p>That&#8217;s not the point behind Genie Fairy Tales, it&#8217;s actually all about  hubris. That&#8217;s why the fairy tales are all most always about the &#8220;third wish&#8221;, the one that undoes the first two wishes&#8230;</p>
<p>Such Fairy Tales are if you prefere about &#8220;listening and following advice and not thinking you are more clever than any one else&#8221;. That is in more modern parlance &#8220;Learning from the past mistakes of others&#8221; something ICTsec repeatedly fails to do&#8230;</p>
<p>The thing that such Fairy Tales always get wrong is that the first two wishes are &#8220;foolish&#8221; but the third is always &#8220;wise&#8221;.</p>
<p>Oddly though, we tend to see &#8220;foolish&#8221; wishes in the likes of finance, where people see only the &#8220;up-side&#8221; of a risk, hardly ever the &#8220;down-side&#8221; of the risk. It kind of tells us something that we mostly miss. Which is such people like gamblers do not understand probability, thus they realy should not be trusted as &#8220;rational actors&#8221;.</p>
<p>The only people that win consistantly at big-win-risk are those not actually taking the risk for one of two basic reasons,</p>
<p>1, The risk is not theirs, but someone elses (ie investor money) they just take a percentage of the transaction.</p>
<p>2, The game is rigged in some way, and they have knowledge others do not (ie they have probably rigged the game).</p>
<p>One of the things that the most visable form of &#8220;AI&#8221; to the public is very sensitive to is &#8220;training data&#8221;. You can if you wish have many sets of &#8220;seed training data&#8221; into which you embed prejudice. Thus with care you can &#8220;rig the game&#8221; so you have a desired prejudicial out come (ie the second point above). But as those using such &#8220;AI Tools&#8221; have &#8220;no skin in the game&#8221; as they in effect get paid and promoted by the rigged system along with an &#8220;Only Following Orders&#8221; excuse built in they have no reason to raise concerns (ie first point avove).</p>
<p>Thus these &#8220;AI Tools&#8221; that get pushed towards the public have both &#8220;big win&#8221; cheats built in, thus they will get pushed and pushed hard and stopping certain people pushing them is going to be hard, very hard, because they win, and those who loose have little or no say&#8230;</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373431">

			<div class="comment by-ismar ">

				<p class="commentcredit">

					<span class="commenter">Ismar</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373431">
						April 26, 2021 6:23 PM					</a>

				</p>

				<p>In short, we have created something we can neither understand nor control and yet are happy to give it more and more room for controlling the way we live.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373432">

			<div class="comment by-rachel ">

				<p class="commentcredit">

					<span class="commenter">Rachel</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373432">
						April 26, 2021 6:46 PM					</a>

				</p>

				<p>The article commences by [mostly] omitting the original definition and application of hacking ðŸ™‚  Defaulting to the more recent and popular ascribed definition. Oh well I suppose that&#8217;s okay.<br />
I would prefer the original and true definition be better appreciated because we as a collective would benefit from applying this perspective in our attitudes to our life and our societal responses.</p>
<p>Naval Ravikant gave an interview with Joe Rogan not long ago.<br />
Brilliant guy, although I disagreed with a number of his points</p>
<p>( mostly the ridiculous Silicon Valley meme-ejaculations, for example  &#8216;Ubber fixed something that was broken and the whole world will run as a gig economy in the future&#8217;. Yes he actually said that )</p>
<p>And I class AI-meme alongside Uber,everything Musk, and a few others being transgressive drivel killing our world.<br />
I&#8217;d like to see a world with no AI.  That&#8217;s what the argument should be. No AI.</p>
<p>Anyway Naval did say that AI was no way near becoming anything even vaguely approximating sentient in our lifetimes or beyond our lifetimes. He said, as someone that was familiar with the work personally, contrary to hype  the development was terribly simplistic. On the level of, data in, data out.</p>
<p>he has written a ton of essays and pieces some of which addresses the scope or lackthereof of AI and there&#8217;s quite a lot on science and quantum stuff.  (And money, he&#8217;s quite fond of and good at &#8216;how to make money&#8217; and explaining what he has learnt.  )</p>
<p><a href="http://www.nav.al" rel="nofollow ugc">http://www.nav.al</a></p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373433">

			<div class="comment by-freezing_in_brazil ">

				<p class="commentcredit">

					<span class="commenter"><a href='https://bravomarques.wordpress.com' rel='external nofollow ugc' class='url'>Freezing_in_Brazil</a></span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373433">
						April 26, 2021 7:12 PM					</a>

				</p>

				<p>@ ï»¿metaschima</p>
<blockquote><p>True AI would be a system that learns on its own and starts making decisions on its own. So far true AI does not exist, but that may change in the near future </p></blockquote>
<p>Agreed. The usual neural network model, tough successful in limited tasks, has reached its limits, imo. Trying to reach AGI through the current ML schemes is something of an almost cargo-cultish quality. I have entertained the idea that evolutionary [as in Darwin] features would have to be introduced into the idea of neural networks. What is missing:</p>
<ol>
<li>Add Sensors to System (5 senses and more), and give it means of expression [printers (2, 3D), monitors, etc.]</li>
<li>Release the system from specific tasks (e.g. Character recognition); The machine is basically an idle entity, free in its neural activity to absorb and correlate information. Let it free to form its own patterns. Let it recognize reality itself, through the senses, in a recursive way, moment by moment.</li>
<li>Refine activation functions, thresholds, incorporating QM features.</li>
<li>Adopt of more general algorithms [or, we might find that true intelligence does not work upon algorithms, and cannot be reproduced programmatically] </li>
</ol>
<p>Intelligence, in nature, and especially in Homo sapiens, derives from the integration of information originating from the senses into the neural pattern. It seems unlikely that it is possible to reach intelligence without the corresponding participation of the senses in the data processing. Hence, I would expect AGI to emerge in a Neuroscience setting, instead of a computer/media lab.</p>
<p>Regards</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment odd alt thread-odd thread-alt depth-1" id="comment-373435">

			<div class="comment by-name-withheld-for-obvious-reasons ">

				<p class="commentcredit">

					<span class="commenter">name.withheld.for.obvious.reasons</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373435">
						April 26, 2021 7:35 PM					</a>

				</p>

				<p>Wonder if the site, Schneier&#8217;s Blog, is a test in the making?</p>
<p>Occam razor seems to apply.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

		<article class="comment even thread-even depth-1" id="comment-373436">

			<div class="comment by-name-withheld-for-obvious-reasons ">

				<p class="commentcredit">

					<span class="commenter">name.withheld.for.obvious.reasons</span> â€¢

					<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/#comment-373436">
						April 26, 2021 7:44 PM					</a>

				</p>

				<p>Oh, wanted to mention that appears the U.S. federal legislative system seems to have enjoyed a hack, speaking of different systems being hack for purposes other than control of hardware (unless of course you&#8217;re talking about human being hardware).</p>
<p>Back during the IAA bill before the house (10 Dec. 2014), files and text were changing on the congressional library site respecting the bill HR4681. Multiple versions of the same bill, different text with different sections rewritten appeared prior to the vote on the bill(s). It was documented here but never got traction. Both Nick P and myself confirmed independently. What we didn&#8217;t know was why and for what purpose.</p>
<p>It is available at the Squid for the second week of Dec in 2014 if memory serves.</p>

				
			</div>

		</article>

		</li><!-- #comment-## -->

	<p class="subscribe-comments">
		<a href="https://www.schneier.com/blog/archives/2021/04/when-ais-start-hacking.html/feed/">
			<img alt="Atom Feed" src="https://149400697.v2.pressablecdn.com/wp-content/themes/schneier/assets/images/rss.png">
			Subscribe to comments on this entry		</a>
	</p>

		<div id="respond" class="comment-respond">
		<h2 class="comments-open-header">Leave a comment <small><a rel="nofollow" id="cancel-comment-reply-link" href="/blog/archives/2021/04/when-ais-start-hacking.html#respond" style="display:none;">Cancel reply</a></small></h2><form action="https://www.schneier.com/wp-comments-post.php" method="post" id="commentform" class="comment-form" novalidate><a href="https://www.schneier.com/wp-login.php?redirect_to=https%3A%2F%2Fwww.schneier.com%2Fblog%2Farchives%2F2021%2F04%2Fwhen-ais-start-hacking.html" title="Login">Login</a><p class="comment-form-author"><label for="author">Name</label> <input id="author" name="author" type="text" value="" size="30" maxlength="245" /></p>
<p class="comment-form-email"><label for="email">Email</label> <input id="email" name="email" type="email" value="" size="30" maxlength="100" /></p>
<p class="comment-form-url"><label for="url">URL:</label> <input id="url" name="url" type="url" value="" size="30" maxlength="200" /></p>
<p class="comment-form-cookies-consent"><input id="wp-comment-cookies-consent" name="wp-comment-cookies-consent" type="checkbox" value="yes" /> <label for="wp-comment-cookies-consent">Remember personal info?</label></p>

<p class="comment-form-author">

	<label for="comm_capt_challenge">
		Fill in the blank: the name of this blog is Schneier on ___________ (required):	</label>

	<input id="comm_capt_challenge" name="comm_capt_challenge" size="30" type="text" />
</p>

<div class="comment-form-comment">

	<label for="comment">Comments:</label>

	<textarea id="comment" name="comment" cols="45" rows="8" maxlength="65525" required="required"></textarea>

	<div id="preview-box" class="preview-box hide"></div>
	<img class="comment-loading hide" src="https://149400697.v2.pressablecdn.com/wp-content/themes/schneier/assets/images/loader.gif" />

</div>

<p id="allowed">

	<strong>Allowed HTML</strong>
	&lt;a href=&quot;URL&quot;&gt; &bull; &lt;em&gt; &lt;cite&gt; &lt;i&gt; &bull; &lt;strong&gt; &lt;b&gt; &bull; &lt;sub&gt; &lt;sup&gt; &bull; &lt;ul&gt; &lt;ol&gt; &lt;li&gt; &bull; &lt;blockquote&gt; &lt;pre&gt;
	<strong>Markdown Extra</strong> syntax via <a href="https://michelf.ca/projects/php-markdown/extra/">https://michelf.ca/projects/php-markdown/extra/</a>
</p>

<input type="hidden" id="wp_comment_nonce" name="wp_comment_nonce" value="f8f7b79ce0" /><input type="hidden" name="_wp_http_referer" value="/blog/archives/2021/04/when-ais-start-hacking.html" />
<input type="button" id="comment-preview" class="comment-preview comment-actions" value="Preview" />
<input type="button" id="comment-write" class="comment-write comment-actions hide" value="Edit" />

<p class="form-submit"><input name="submit" type="submit" id="submit" class="submit" value="Submit" /> <input type='hidden' name='comment_post_ID' value='62199' id='comment_post_ID' />
<input type='hidden' name='comment_parent' id='comment_parent' value='0' />
</p></form>	</div><!-- #respond -->
	
	<div class="stepthrough">
		<a href="https://www.schneier.com/blog/archives/2021/04/friday-squid-blogging-squid-shaped-bike-rack.html" rel="prev">â† Friday Squid Blogging: Squid-Shaped Bike Rack</a>			</div>

	
<p id="powered">Sidebar photo of Bruce Schneier by Joe MacInnis.</p>
		</div>

		
<aside>
	<div class="sidebar" id="sidebar-two">
		<section><div class="sidesection widget widget_schneier_about" id="schneier_about-2"><h3>About Bruce Schneier</h3><img src="https://149400697.v2.pressablecdn.com/wp-content/uploads/2019/10/Bruce-Schneier.jpg" /><p><p class="small">I am a <a href="https://public-interest-tech.com/">public-interest technologist</a>, working at the intersection of security, technology, and people. I've been writing about security issues on my <a href="/">blog</a> since 2004, and in my monthly <a href="/crypto-gram/">newsletter</a> since 1998. I'm a fellow and lecturer at Harvard's <a href="https://www.hks.harvard.edu/faculty/bruce-schneier">Kennedy School</a>, a board member of <a href="https://www.eff.org/">EFF</a>, and the Chief of Security Architecture at <a href="https://inrupt.com/">Inrupt, Inc.</a> This personal website expresses the opinions of none of those organizations.</p>
</p></div></section><section><div class="sidesection widget widget_schneier_related_posts" id="schneier_related_posts-2"><h3>Related Entries</h3>
<ul>

	<li><a href="https://www.schneier.com/blog/archives/2021/04/cybersecurity-experts-to-follow-on-twitter.html">Cybersecurity Experts to Follow on Twitter</a></li><li><a href="https://www.schneier.com/blog/archives/2021/04/wi-fi-devices-as-physical-object-sensors.html">Wi-Fi Devices as Physical Object Sensors</a></li><li><a href="https://www.schneier.com/blog/archives/2021/04/fugitive-identified-on-youtube-by-his-distinctive-tattoos.html">Fugitive Identified on YouTube By His Distinctive Tattoos</a></li><li><a href="https://www.schneier.com/blog/archives/2021/03/determining-key-shape-from-sound.html">Determining Key Shape from Sound</a></li><li><a href="https://www.schneier.com/blog/archives/2021/03/security-analysis-of-apples-find-my-protocol.html">Security Analysis of Apple&#039;s &quot;Find My...&quot; Protocol</a></li><li><a href="https://www.schneier.com/blog/archives/2021/03/metadata-left-in-security-agency-pdfs.html">Metadata Left in Security Agency PDFs</a></li>
</ul>
</div></section><section><div class="sidesection widget widget_schneier_featured_essays" id="schneier_featured_essays-2"><h3>Featured Essays</h3>
	<ul>
		<li><a href="https://www.schneier.com/essays/archives/2016/04/the_value_of_encrypt.html">The Value of Encryption</a></li><li><a href="https://www.schneier.com/essays/archives/2016/03/data_is_a_toxic_asse.html">Data Is a Toxic Asset, So Why Not Throw It Out?</a></li><li><a href="https://www.schneier.com/essays/archives/2014/01/how_the_nsa_threaten.html">How the NSA Threatens National Security</a></li><li><a href="https://www.schneier.com/essays/archives/2009/01/terrorists_may_use_g.html">Terrorists May Use Google Earth, But Fear Is No Reason to Ban It</a></li><li><a href="https://www.schneier.com/essays/archives/2007/01/in_praise_of_securit.html">In Praise of Security Theater</a></li><li><a href="https://www.schneier.com/essays/archives/2006/08/refuse_to_be_terrori.html">Refuse to be Terrorized</a></li><li><a href="https://www.schneier.com/essays/archives/2006/05/the_eternal_value_of.html">The Eternal Value of Privacy</a></li><li><a href="https://www.schneier.com/essays/archives/2005/09/terrorists_dont_do_m.html">Terrorists Don&#039;t Do Movie Plots</a></li>	</ul>

	<p><a href="https://www.schneier.com/essays/">More Essays</a></p></div></section><section><div class="sidesection widget widget_schneier_archives" id="schneier_archives-2"><h3>Blog Archives</h3>
<ul>

	<li><a href="https://www.schneier.com/blog/calendar.html/">Archive by Month</a></li><li><a href="https://www.schneier.com/blog/newcomments.html/">100 Latest Comments</a></li></ul>

<h4>Blog Tags</h4><ul class="top-tags"><li><a href="https://www.schneier.com/tag/3d-printers/">3d printers</a></li><li><a href="https://www.schneier.com/tag/9-11/">9/11</a></li><li><a href="https://www.schneier.com/tag/aaron-swartz/">Aaron Swartz</a></li><li><a href="https://www.schneier.com/tag/academic/">academic</a></li><li><a href="https://www.schneier.com/tag/academic-papers/">academic papers</a></li><li><a href="https://www.schneier.com/tag/accountability/">accountability</a></li><li><a href="https://www.schneier.com/tag/aclu/">ACLU</a></li><li><a href="https://www.schneier.com/tag/activism/">activism</a></li><li><a href="https://www.schneier.com/tag/adobe/">Adobe</a></li><li><a href="https://www.schneier.com/tag/advanced-persistent-threats/">advanced persistent threats</a></li><li><a href="https://www.schneier.com/tag/adware/">adware</a></li><li><a href="https://www.schneier.com/tag/aes/">AES</a></li><li><a href="https://www.schneier.com/tag/afghanistan/">Afghanistan</a></li><li><a href="https://www.schneier.com/tag/air-marshals/">air marshals</a></li><li><a href="https://www.schneier.com/tag/air-travel/">air travel</a></li><li><a href="https://www.schneier.com/tag/airgaps/">airgaps</a></li><li><a href="https://www.schneier.com/tag/al-qaeda/">al Qaeda</a></li><li><a href="https://www.schneier.com/tag/alarms/">alarms</a></li><li><a href="https://www.schneier.com/tag/algorithms/">algorithms</a></li><li><a href="https://www.schneier.com/tag/alibis/">alibis</a></li><li><a href="https://www.schneier.com/tag/amazon/">Amazon</a></li><li><a href="https://www.schneier.com/tag/android/">Android</a></li><li><a href="https://www.schneier.com/tag/anonymity/">anonymity</a></li><li><a href="https://www.schneier.com/tag/anonymous/">Anonymous</a></li><li><a href="https://www.schneier.com/tag/antivirus/">antivirus</a></li><li><a href="https://www.schneier.com/tag/apache/">Apache</a></li><li><a href="https://www.schneier.com/tag/apple/">Apple</a></li><li><a href="https://www.schneier.com/tag/applied-cryptography/">Applied Cryptography</a></li><li><a href="https://www.schneier.com/tag/artificial-intelligence/">artificial intelligence</a></li><li><a href="https://www.schneier.com/tag/assassinations/">assassinations</a></li></ul><p><a href="https://www.schneier.com/blog/tags.html/">More Tags</a></p></div></section><section><div class="sidesection widget widget_schneier_latest_book" id="schneier_latest_book-3"><h3>Latest Book</h3><a href="https://www.schneier.com/books/click-here/"><img class="sidepic" alt="Click Here to Kill Everybody" src="https://149400697.v2.pressablecdn.com/wp-content/uploads/2018/07/book-ch2-200w.png" /></a><p><a href="https://www.schneier.com/books/">More Books</a></p></div></section><section><div class="sidesection widget widget_schneier_promotion" id="schneier_promotion-2">
<a href="https://www.eff.org/issues/bloggers/legal/join">
	<img src="https://149400697.v2.pressablecdn.com/wp-content/themes/schneier/assets/images/join-eff@2x.png" id="effbutton" alt="Support Bloggers' Rights!" title="Support Bloggers' Rights!" /></a>

<a href="https://npo.networkforgood.org/Donate/Donate.aspx?npoSubscriptionId=8252">
	<img src="https://149400697.v2.pressablecdn.com/wp-content/themes/schneier/assets/images/support-epic@2x.png" alt="Defend Privacy--Support Epic" title="Defend Privacy--Support Epic" /></a>
</div></section>	</div>
</aside>

		<footer>
			<nav>
				<div class="nav" id="footer-nav">
					<div class="menu-main-menu-container"><ul id="menu-main-menu-1" class="menu"><li class="menu1 menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-50175 current-menu-item"><a href="https://www.schneier.com">Blog</a></li>
<li class="menu2 menu-item menu-item-type-post_type menu-item-object-page menu-item-50916"><a href="https://www.schneier.com/crypto-gram/">Newsletter</a></li>
<li class="menu3 menu-item menu-item-type-post_type menu-item-object-page menu-item-50166"><a href="https://www.schneier.com/books/">Books</a></li>
<li class="menu4 menu-item menu-item-type-custom menu-item-object-custom menu-item-50169"><a href="https://www.schneier.com/essays/">Essays</a></li>
<li class="menu5 menu-item menu-item-type-custom menu-item-object-custom menu-item-50170"><a href="https://www.schneier.com/news/">News</a></li>
<li class="menu6 menu-item menu-item-type-custom menu-item-object-custom menu-item-50171"><a href="https://www.schneier.com/talks/">Talks</a></li>
<li class="menu7 menu-item menu-item-type-post_type menu-item-object-page menu-item-50167"><a href="https://www.schneier.com/academic/">Academic</a></li>
<li class="menu8 menu-item menu-item-type-post_type menu-item-object-page menu-item-50174"><a href="https://www.schneier.com/blog/about/">About Me</a></li>
</ul></div>				</div>
			</nav>
		</footer>

		</div><!--#main-->
	</div><!--#wrapper-->

		<script type="text/javascript">
		(function () {
			var c = document.body.className;
			c = c.replace(/woocommerce-no-js/, 'woocommerce-js');
			document.body.className = c;
		})();
	</script>
	<script type='text/javascript' src='https://c0.wp.com/p/woocommerce/5.1.0/assets/js/jquery-cookie/jquery.cookie.min.js' id='jquery-cookie-js'></script>
<script type='text/javascript' src='https://149400697.v2.pressablecdn.com/wp-content/themes/schneier/assets/vendor/socialshareprivacy/js/socialshareprivacy.js?ver=1.0.1' id='social-share-privacy-js'></script>
<script type='text/javascript' id='social-share-privacy-icons-js-extra'>
/* <![CDATA[ */
var schneierSocial = {"path":"https:\/\/www.schneier.com\/wp-content\/themes\/schneier\/assets\/vendor\/socialshareprivacy\/"};
/* ]]> */
</script>
<script type='text/javascript' src='https://149400697.v2.pressablecdn.com/wp-content/themes/schneier/assets/vendor/socialshareprivacy/js/icons.js?ver=1.0.0' id='social-share-privacy-icons-js'></script>
<script type='text/javascript' id='schneier-comment-js-extra'>
/* <![CDATA[ */
var schneierComment = {"translateErrorSecurityAnswerWrong":"Your response to the challenge question ('The name of this blog is Schneier on ____') was not correct. Please try again.","ajax_url":"https:\/\/www.schneier.com\/wp-admin\/admin-ajax.php"};
/* ]]> */
</script>
<script type='text/javascript' src='https://149400697.v2.pressablecdn.com/wp-content/themes/schneier/assets/js/comment.js?ver=1.0.1' id='schneier-comment-js'></script>
<script type='text/javascript' src='https://c0.wp.com/c/5.7.1/wp-includes/js/wp-embed.min.js' id='wp-embed-js'></script>

</body>

</html>
<!--
	generated 95 seconds ago
	generated in 0.228 seconds
	served from batcache in 0.002 seconds
	expires in 205 seconds
-->
